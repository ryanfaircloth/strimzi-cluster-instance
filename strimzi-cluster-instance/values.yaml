# Default values for strimzi-cluster-instance.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# This is to override the chart name.
fullnameOverride: ""
nameOverride: ""

# Default topology spread key for pod distribution across nodes
# Use "topology.kubernetes.io/zone" for production to spread across availability zones
# Use "kubernetes.io/hostname" to spread across individual nodes
defaultTopologySpreadKey: "topology.kubernetes.io/zone"

# Default architecture for node affinity
# Set to "arm64" or "amd64" (also known as "x86_64")
defaultArchitecture: "arm64"

# Node pools configuration
nodePools:
  - name: broker
    roles:
      - broker
    replicas: 3
    additionalAnnotations:
      strimzi.io/next-node-ids: "[0-499]"
    # Additional match expressions to add to the default node affinity
    # This allows adding constraints without managing the full affinity config
    additionalNodeMatchExpressions: []
    # Example:
    # additionalNodeMatchExpressions:
    #   - key: node.kubernetes.io/instance-type
    #     operator: In
    #     values:
    #       - m5.large
    #       - m5.xlarge
    template:
      pod:
        metadata:
          labels:
            app.kubernetes.io/component: broker
        affinity:
          podAffinity: {}
          podAntiAffinity: {}
        tolerations: []
        topologySpreadConstraints: []
        priorityClassName: ""
        tmpDirSizeLimit: ""
        volumes: []
    storage:
      type: jbod
      volumes:
        - id: 0
          type: ephemeral
  #   storage:
  #     type: jbod
  #     volumes:
  #       - id: 0
  #         type: persistent-claim
  #         size: 64Gi
  #         # Indicates that this directory will be used to store Kraft metadata log
  #         kraftMetadata: shared
  #         deleteClaim: false
  #       - id: 1
  #         type: persistent-claim
  #         size: 64Gi
  #         deleteClaim: false
    # Resource requests and limits for broker pods
    # Set to null or {} to omit resource constraints (not recommended for production)
    resources:
      requests:
        memory: "2Gi"
        cpu: "1"
      # limits:
      #   memory: "4Gi"
      #   cpu: "2000m"
    # JVM options for broker pods following Strimzi best practices.
    # -Xms=-Xmx avoids costly heap resize; sized to ~50 % of the pod memory request.
    # G1GC with MaxGCPauseMillis=20 and IHOP=35 matches Confluent/Kafka tuning guidance.
    # Set to {} or omit to use Strimzi defaults.
    jvmOptions:
      "-Xms": "1g"
      "-Xmx": "1g"
      gcLoggingEnabled: false
      "-XX":
        MaxGCPauseMillis: "20"
        InitiatingHeapOccupancyPercent: "35"
        ExplicitGCInvokesConcurrent: "true"
  
  - name: controller
    roles:
      - controller
    replicas: 3
    additionalAnnotations:
      strimzi.io/next-node-ids: "[500-600]"
    # Additional match expressions to add to the default node affinity
    additionalNodeMatchExpressions: []
    template:
      pod:
        metadata:
          labels:
            app.kubernetes.io/component: controller
        affinity:
          podAffinity: {}
          podAntiAffinity: {}
        tolerations: []
        topologySpreadConstraints: []
        priorityClassName: ""
        tmpDirSizeLimit: ""
        volumes: []
    storage:
      type: jbod
      volumes:
        - id: 0
          type: ephemeral
          sizeLimit: 64Gi
          kraftMetadata: shared  
  #   storage:
  #     type: jbod
  #     volumes:
  #       - id: 0
  #         type: persistent-claim
  #         size: 64Gi
  #         # Indicates that this directory will be used to store Kraft metadata log
  #         kraftMetadata: shared
  #         deleteClaim: false
    # Resource requests and limits for controller pods
    # Set to null or {} to omit resource constraints (not recommended for production)
    resources:
      requests:
        memory: "2Gi"
        cpu: "1"
      # limits:
      #   memory: "2Gi"
      #   cpu: "1000m"
    # JVM options for controller pods; sized identically to brokers.
    # Set to {} or omit to use Strimzi defaults.
    jvmOptions:
      "-Xms": "1g"
      "-Xmx": "1g"
      gcLoggingEnabled: false
      "-XX":
        MaxGCPauseMillis: "20"
        InitiatingHeapOccupancyPercent: "35"
        ExplicitGCInvokesConcurrent: "true"

# Kafka CR settings
kafka:
  additionalAnnotations: {}
  additionalLabels: {}
  brokerRackInitImage: null
  
  config:
    auto.create.topics.enable: true
    # background threads include replication for very high throughput increase based on available CPU cores and usage default is 10
    # background.threads: 20
    default.replication.factor: 2
    # For storage where storage is thin provisioned enable
    # log.preallocate: true
    min.insync.replicas: 2
    # num.io.threads increase based on available CPU cores and usage default is 8
    # num.io.threads: 20
    # num.network.threads increase based on available CPU cores and usage default is 3
    # num.network.threads: 6
    # num.recovery.threads.per.data.dir: 2  # default is 1 set to number of cores in brokers
    # num.recovery.threads.per.data.dir: 1
    # num.replica.fetchers increase based on available CPU cores and usage default is 1
    # num.replica.fetchers: 10
    offsets.topic.replication.factor: 3
    replica.selector.class: org.apache.kafka.common.replica.RackAwareReplicaSelector
    # replica.socket.receive.buffer.bytes: 65536 increased for higher replication throughput based on memory
    # replica.socket.receive.buffer.bytes: 1000000
    # socket.receive.buffer.bytes: 102400 default setting to -1 to use OS default
    socket.receive.buffer.bytes: -1
    # socket.request.max.bytes: 104857600 default setting to 100MB probably should not change
    # socket.send.buffer.bytes: 102400 default setting to -1 to use OS default
    socket.send.buffer.bytes: -1
    transaction.state.log.min.isr: 2
    transaction.state.log.replication.factor: 3
  jmxOptions: {}

  # metricsConfig configures Prometheus metrics on broker and controller pods.
  # Recommended: strimziMetricsReporter (available since Strimzi 0.47.0).
  # Set to {} or omit to disable metrics.
  #
  # Example — Strimzi Metrics Reporter (preferred):
  #   metricsConfig:
  #     type: strimziMetricsReporter
  #     values:
  #       allowList:
  #         - "kafka_server_brokertopicmetrics.*"
  #         - "kafka_network_requestmetrics.*"
  #         - "kafka_controller.*"
  #
  # Example — legacy JMX Prometheus Exporter:
  #   metricsConfig:
  #     type: jmxPrometheusExporter
  #     valueFrom:
  #       configMapKeyRef:
  #         name: kafka-metrics
  #         key: kafka-metrics-config.yml
  metricsConfig: {}

  # logging configures the log4j2 configuration for broker and controller pods.
  # When set to a non-empty map it takes full precedence over the top-level
  # `logging` defaults (see below).  Set to {} to inherit the shared defaults.
  #
  # Example — inline loggers (level overrides only, no layout control):
  #   logging:
  #     type: inline
  #     loggers:
  #       rootLogger.level: DEBUG
  #
  # Example — reference a custom ConfigMap:
  #   logging:
  #     type: external
  #     valueFrom:
  #       configMapKeyRef:
  #         name: my-log4j2-config
  #         key: log4j2.properties
  logging: {}

  listeners:
    tls:
      port: 9093
      authentication:
        type: scram-sha-512
    tlsext: # Enable TLS listener for external access by enabling gateway
      port: 9094
      type: cluster-ip
      authentication:
        type: scram-sha-512
  metadataVersion: null
  rack:
    topologyKey: topology.kubernetes.io/zone

  cruiseControl:
    brokerCapacity:
      inboundNetwork: 15728640KiB/s
      outboundNetwork: 15728640KiB/s
    config: {}
    # JVM options for CruiseControl; sized to ~50 % of its memory request (1 Gi → 512 m).
    # Set to {} or omit to use Strimzi defaults.
    jvmOptions:
      "-Xms": "512m"
      "-Xmx": "512m"
      gcLoggingEnabled: false
      "-XX":
        MaxGCPauseMillis: "20"
        InitiatingHeapOccupancyPercent: "35"
        ExplicitGCInvokesConcurrent: "true"
    # logging configures log4j2 for CruiseControl.
    # When set to a non-empty map it takes full precedence over the top-level
    # `logging` defaults.  Set to {} to inherit the shared defaults.
    logging: {}
    # Additional match expressions to add to the default node affinity for Cruise Control
    additionalNodeMatchExpressions: []
    template:
      pod:
        metadata:
          labels:
            app.kubernetes.io/component: cruise-control
        affinity: {}
        tolerations: []
        topologySpreadConstraints: []
        priorityClassName: ""
        tmpDirSizeLimit: ""
        volumes: []
    # Resource requests and limits for CruiseControl
    # Set to null or {} to omit resource constraints (not recommended for production)
    resources:
      requests:
        memory: "1Gi"
        cpu: "1"
      # limits:
      #   memory: "2Gi"
      #   cpu: "1"
  entityOperator:
    # Additional match expressions to add to the default node affinity for Entity Operator
    additionalNodeMatchExpressions: []
    template:
      pod:
        metadata:
          labels:
            app.kubernetes.io/component: entity-operator
        affinity: {}
        tolerations: []
        topologySpreadConstraints: []
        priorityClassName: ""
        tmpDirSizeLimit: ""
        volumes: []
    topicOperator:
      watchAnyNamespace: false
      # Set watchedNamespace to the namespace where the operator should watch for resources
      # If empty, the operator will use the release namespace
      watchedNamespace: ""
      # Resource requests and limits for topic operator
      # Set to null or {} to omit resource constraints (not recommended for production)
      resources:
        requests:
          memory: "512Mi"
          cpu: "250m"
        # limits:
        #   memory: "1Gi"
        #   cpu: "500m"
      # JVM options for the Topic Operator; sized to ~50 % of its memory request.
      # Set to {} or omit to use Strimzi defaults.
      jvmOptions:
        "-Xms": "256m"
        "-Xmx": "256m"
        gcLoggingEnabled: false
      # logging configures log4j2 for the Topic Operator.
      # When set to a non-empty map it takes full precedence over the top-level
      # `logging` defaults.  Set to {} to inherit the shared defaults.
      logging: {}
    userOperator:
      watchAnyNamespace: false
      # Set watchedNamespace to the namespace where the operator should watch for resources
      # If empty, the operator will use the release namespace
      watchedNamespace: ""
      # Resource requests and limits for user operator
      # Set to null or {} to omit resource constraints (not recommended for production)
      resources:
        requests:
          memory: "512Mi"
          cpu: "250m"
        # limits:
        #   memory: "1Gi"
        #   cpu: "500m"
      # JVM options for the User Operator; sized to ~50 % of its memory request.
      # Set to {} or omit to use Strimzi defaults.
      jvmOptions:
        "-Xms": "256m"
        "-Xmx": "256m"
        gcLoggingEnabled: false
      # logging configures log4j2 for the User Operator.
      # When set to a non-empty map it takes full precedence over the top-level
      # `logging` defaults.  Set to {} to inherit the shared defaults.
      logging: {}
    version: null

  podMonitor:
    # Set enabled: true when metricsConfig.type is strimziMetricsReporter
    enabled: false
    # Prometheus Operator namespace selector — set to the namespace where your
    # Prometheus/VictoriaMetrics operator is installed.
    namespaceSelector:
      any: true
    # Scrape interval
    interval: "30s"
    # Port name exposed by strimziMetricsReporter (default: tcp-prometheus)
    portName: "tcp-prometheus"
    # Additional labels to apply to the PodMonitor resource
    additionalLabels: {}

# Logging configuration for all Strimzi components.
#
# When log4j2Properties is non-empty, a ConfigMap is generated per component
# and each component is configured with `logging.type: external` pointing to it.
# This enables JSON-format structured logging throughout the cluster.
#
# Per-component inline Strimzi logging specs (kafka.logging,
# kafka.cruiseControl.logging, kafka.entityOperator.topicOperator.logging, and
# kafka.entityOperator.userOperator.logging) take full precedence when non-empty.
#
# To revert a component to Strimzi defaults, set its component-level logging
# to a non-empty inline spec, e.g.: logging: { type: inline, loggers: {} }
logging:
  # Default log4j2.properties applied to every component.
  # Set to "" to disable JSON logging overrides globally.
  log4j2Properties: |
    name=COConfig
    monitorInterval=30

    appender.console.type=Console
    appender.console.name=STDOUT
    appender.console.layout.type=JsonTemplateLayout

    rootLogger.level=INFO
    rootLogger.appenderRefs=stdout
    rootLogger.appenderRef.stdout.ref=STDOUT

  # Per-component overrides. When log4j2Properties is non-empty it replaces
  # the shared default above for that component only.
  # Set a component's log4j2Properties to "" to fall back to the shared default.
  kafka:
    log4j2Properties: |
      name=COConfig
      monitorInterval=30

      appender.console.type=Console
      appender.console.name=STDOUT
      appender.console.layout.type=JsonTemplateLayout

      rootLogger.level=INFO
      rootLogger.appenderRefs=stdout
      rootLogger.appenderRef.stdout.ref=STDOUT
  topicOperator:
    log4j2Properties: |
      name=COConfig
      monitorInterval=30

      appender.console.type=Console
      appender.console.name=STDOUT
      appender.console.layout.type=JsonTemplateLayout

      rootLogger.level=INFO
      rootLogger.appenderRefs=stdout
      rootLogger.appenderRef.stdout.ref=STDOUT
  userOperator:
    log4j2Properties: |
      name=COConfig
      monitorInterval=30

      appender.console.type=Console
      appender.console.name=STDOUT
      appender.console.layout.type=JsonTemplateLayout

      rootLogger.level=INFO
      rootLogger.appenderRefs=stdout
      rootLogger.appenderRef.stdout.ref=STDOUT
  cruiseControl:
    log4j2Properties: |
      name=COConfig
      monitorInterval=30

      appender.console.type=Console
      appender.console.name=STDOUT
      appender.console.layout.type=JsonTemplateLayout

      rootLogger.level=INFO
      rootLogger.appenderRefs=stdout
      rootLogger.appenderRef.stdout.ref=STDOUT

kafkaRebalance:
  enabled: true
  additionalAnnotations: {}
  additionalLabels: {}
  skipHardGoalCheck: false
  goals:
    - NetworkInboundCapacityGoal
    - DiskCapacityGoal
    - RackAwareGoal
    - NetworkOutboundCapacityGoal
    - CpuCapacityGoal
    - ReplicaCapacityGoal

# Periodic automated rebalance via a Kubernetes CronJob.
#
# When enabled, this creates:
#   - A dedicated KafkaRebalance CR  (<release>-periodic)
#   - A ServiceAccount / Role / RoleBinding for the CronJob
#   - A CronJob that triggers a fresh Cruise Control proposal on a cron schedule
#
# Best-practice goal ordering (Strimzi / LinkedIn guidance):
#   Hard capacity goals fire first, then distribution/optimisation goals.
#   This ensures no broker is ever overloaded before partitions are spread evenly.
#
# Compatibility: autoApproval requires Strimzi >= 0.41.  For older operators set
#   autoApproval: false — the CronJob will wait for ProposalReady and then apply
#   the approve annotation automatically.
kafkaRebalanceAuto:
  enabled: false

  # Cron schedule (UTC).  Default: daily at 02:00.
  # Tune to a low-traffic window for your cluster.
  schedule: "0 2 * * *"

  additionalAnnotations: {}
  additionalLabels: {}

  # skipHardGoalCheck: false — hard capacity goals (network/disk/CPU/replica) are
  # always enforced.  Setting true risks overloading brokers and is not recommended.
  skipHardGoalCheck: false

  # autoApproval: when true the Strimzi operator automatically approves the Cruise
  # Control proposal and executes the rebalance (requires Strimzi >= 0.41).
  # When false the CronJob waits for ProposalReady and applies the approve annotation.
  autoApproval: true

  # mode: full — rebalances all partition replicas across all brokers.
  # Other values: add-brokers, remove-brokers (used during scaling events).
  mode: full

  # rebalanceDisk: set to true when using JBOD storage to also balance disk usage
  # across volumes within each broker (intra-broker rebalance).
  rebalanceDisk: false

  # Goals in priority order — hard capacity goals first, then distribution goals.
  # Hard goals (must not be violated):
  #   NetworkInboundCapacityGoal, DiskCapacityGoal, RackAwareGoal,
  #   NetworkOutboundCapacityGoal, CpuCapacityGoal, ReplicaCapacityGoal
  # Soft / distribution goals (optimise spread across brokers):
  #   ReplicaDistributionGoal, PotentialNwOutGoal, DiskUsageDistributionGoal,
  #   NetworkInboundUsageDistributionGoal, NetworkOutboundUsageDistributionGoal,
  #   TopicReplicaDistributionGoal, LeaderReplicaDistributionGoal,
  #   LeaderBytesInDistributionGoal, PreferredLeaderElectionGoal
  goals:
    # --- Hard capacity goals (never violate) ---
    - NetworkInboundCapacityGoal
    - DiskCapacityGoal
    - RackAwareGoal
    - NetworkOutboundCapacityGoal
    - CpuCapacityGoal
    - ReplicaCapacityGoal
    # --- Distribution / optimisation goals ---
    - ReplicaDistributionGoal
    - PotentialNwOutGoal
    - DiskUsageDistributionGoal
    - NetworkInboundUsageDistributionGoal
    - NetworkOutboundUsageDistributionGoal
    - TopicReplicaDistributionGoal
    - LeaderReplicaDistributionGoal
    - LeaderBytesInDistributionGoal
    - PreferredLeaderElectionGoal

  cronJob:
    # kubectl-compatible image.  Pin the tag to match your cluster's Kubernetes version
    # (e.g. "1.32" for Kubernetes 1.32.x) for API compatibility.
    image:
      repository: bitnami/kubectl
      tag: "1.32"

    # How long (seconds) to wait for a Cruise Control proposal before the job fails.
    # Only relevant when autoApproval: false.
    proposalWaitTimeout: "600"

    # Job retry limit on transient failures (API server blips, etc.)
    backoffLimit: 3

    # Hard deadline for the entire job in seconds (proposal wait + rebalance execution).
    # Default 4 h — increase for very large clusters.
    activeDeadlineSeconds: 14400

    successfulJobsHistoryLimit: 3
    failedJobsHistoryLimit: 3

    # Resource requests/limits for the kubectl trigger container.
    # The container only runs shell + kubectl so very low resources are sufficient.
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"
        cpu: "100m"

    tolerations: []
    nodeSelector: {}

# Gateway configuration
gateway:
  enabled: false
  dnsSuffix: "strimzi.gateway.api.test"
  certificate:
    enabled: true
    issuerRef:
      name: cluster-ca-issuer
      kind: ClusterIssuer
    subject:
      organizations:
      - my-org
    privateKey:
      algorithm: ECDSA
      encoding: PKCS8
      size: 256
    usages:
    - server auth
    - client auth

# Users configuration
users:
  enableAdminUser: false
  adminUser:
    name: admin
    authentication:
      type: scram-sha-512